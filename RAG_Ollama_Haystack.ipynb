{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install haystack-ai#==2.2.4\n",
        "!pip install haystack-experimental#==0.1.0\n",
        "!pip install sentence-transformers#==3.0.1\n",
        "!pip install transformers#==4.42.3\n",
        "!pip install ollama-haystack"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUJbsVpBeHgl",
        "outputId": "53b2dd56-9464-4e6b-e7a8-444454263b23"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105\n",
            "\u001b[31mERROR: Invalid requirement: '==': Expected package name at the start of dependency specifier\n",
            "    ==\n",
            "    ^\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Invalid requirement: '==': Expected package name at the start of dependency specifier\n",
            "    ==\n",
            "    ^\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Invalid requirement: '==': Expected package name at the start of dependency specifier\n",
            "    ==\n",
            "    ^\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Invalid requirement: '==': Expected package name at the start of dependency specifier\n",
            "    ==\n",
            "    ^\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting ollama-haystack\n",
            "  Downloading ollama_haystack-0.0.7-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: haystack-ai in /usr/local/lib/python3.10/dist-packages (from ollama-haystack) (2.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ollama-haystack) (2.32.3)\n",
            "Requirement already satisfied: haystack-experimental in /usr/local/lib/python3.10/dist-packages (from haystack-ai->ollama-haystack) (0.1.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from haystack-ai->ollama-haystack) (3.1.4)\n",
            "Requirement already satisfied: lazy-imports in /usr/local/lib/python3.10/dist-packages (from haystack-ai->ollama-haystack) (0.3.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from haystack-ai->ollama-haystack) (10.3.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from haystack-ai->ollama-haystack) (3.3)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from haystack-ai->ollama-haystack) (1.26.4)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from haystack-ai->ollama-haystack) (1.42.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from haystack-ai->ollama-haystack) (2.1.4)\n",
            "Requirement already satisfied: posthog in /usr/local/lib/python3.10/dist-packages (from haystack-ai->ollama-haystack) (3.5.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from haystack-ai->ollama-haystack) (2.8.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from haystack-ai->ollama-haystack) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0 in /usr/local/lib/python3.10/dist-packages (from haystack-ai->ollama-haystack) (9.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from haystack-ai->ollama-haystack) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from haystack-ai->ollama-haystack) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ollama-haystack) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ollama-haystack) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ollama-haystack) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ollama-haystack) (2024.7.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->haystack-ai->ollama-haystack) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->haystack-ai->ollama-haystack) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->haystack-ai->ollama-haystack) (0.27.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->haystack-ai->ollama-haystack) (0.5.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->haystack-ai->ollama-haystack) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->haystack-ai->ollama-haystack) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->haystack-ai->ollama-haystack) (2.1.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->haystack-ai->ollama-haystack) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->haystack-ai->ollama-haystack) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->haystack-ai->ollama-haystack) (1.16.0)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog->haystack-ai->ollama-haystack) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog->haystack-ai->ollama-haystack) (2.2.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->haystack-ai->ollama-haystack) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.1.0->haystack-ai->ollama-haystack) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.1.0->haystack-ai->ollama-haystack) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->haystack-ai->ollama-haystack) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->haystack-ai->ollama-haystack) (2.20.1)\n",
            "Downloading ollama_haystack-0.0.7-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: ollama-haystack\n",
            "Successfully installed ollama-haystack-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "X3Ain4FzcZWd"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "import torch\n",
        "\n",
        "from haystack_integrations. components.generators.ollama import OllamaGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator = OllamaGenerator(model=\"llama3.1\",\n",
        "  url = \"http://103.220.68.101:11434/api/generate\",\n",
        "  generation_kwargs={\n",
        "    \"num_predict\": 100,\n",
        "    \"temperature\": 0.9,\n",
        "  })"
      ],
      "metadata": {
        "id": "5Y-kggDQcnnD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generator. run(\"Who is the best American actor?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AenyiQ9cyuI",
        "outputId": "d77b6765-c94a-46b2-989a-8ae2b85f7dec"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'replies': ['A question that\\'s sure to spark some debate!\\n\\nChoosing the \"best\" American actor is subjective and often depends on personal opinions, preferences, and criteria for evaluation. Here are a few possible approaches:\\n\\n1. **Critical acclaim**: Consider actors who have received numerous awards and nominations from reputable organizations like the Academy Awards (Oscars), Golden Globes, BAFTAs, and Critics\\' Choice Movie Awards.\\n2. **Box office success**: Look at actors who have consistently delivered hits at the box'], 'meta': [{'model': 'llama3.1', 'created_at': '2024-08-26T02:33:25.3260738Z', 'done': True, 'done_reason': 'length', 'context': [128009, 128006, 882, 128007, 271, 15546, 374, 279, 1888, 3778, 12360, 30, 128009, 128006, 78191, 128007, 271, 32, 3488, 430, 596, 2771, 311, 15541, 1063, 11249, 2268, 96144, 279, 330, 16241, 1, 3778, 12360, 374, 44122, 323, 3629, 14117, 389, 4443, 18463, 11, 19882, 11, 323, 13186, 369, 16865, 13, 5810, 527, 264, 2478, 3284, 20414, 1473, 16, 13, 3146, 43108, 97963, 96618, 21829, 20142, 889, 617, 4036, 12387, 23146, 323, 60698, 505, 56940, 11351, 1093, 279, 16192, 23488, 320, 46, 2445, 1590, 705, 18288, 63388, 288, 11, 34589, 4082, 2170, 11, 323, 77513, 6, 28206, 14270, 23488, 627, 17, 13, 3146, 1642, 5274, 2450, 96618, 9372, 520, 20142, 889, 617, 21356, 12886, 13280, 520, 279, 3830], 'total_duration': 30426414000, 'load_duration': 6543270300, 'prompt_eval_count': 18, 'prompt_eval_duration': 1050359000, 'eval_count': 100, 'eval_duration': 22830442000}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack_integrations. components.generators.ollama import OllamaGenerator\n",
        "from haystack import Pipeline, Document\n",
        "from haystack. components. retrievers. in_memory import InMemoryBM25Retriever\n",
        "from haystack. components. builders. prompt_builder import PromptBuilder\n",
        "from haystack. document_stores. in_memory import InMemoryDocumentStore"
      ],
      "metadata": {
        "id": "LCscFteoehOe"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "Given the following information, answer the question.\n",
        "\n",
        "Context:\n",
        "{% for document in documents %}\n",
        "{{ document.content }}\n",
        "{% endfor %}\n",
        "\n",
        "Question: {{ query }}?\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "5JeZS_laemT5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docstore = InMemoryDocumentStore()\n",
        "# docstore.write_documents([Document(content=\"I really like summer\"),\n",
        "#                           Document (content=\"My favorite sport is soccer\"),\n",
        "#                           Document (content=\"I don't like reading sci-fi books\"),\n",
        "#                           Document (content=\"I don't like crowded places\") , ])\n",
        "\n",
        "docstore.write_documents([Document(content=\"T√¥i th√≠ch m√πa h√®\"),\n",
        "                          Document(content=\"M√¥n th·ªÉ thao y√™u th√≠ch c·ªßa t√¥i l√† b√≥ng ƒë√°\"),\n",
        "                          Document(content=\"T√¥i kh√¥ng th√≠ch ƒë·ªçc s√°ch khoa h·ªçc vi·ªÖn t∆∞·ªüng\"),\n",
        "                          Document(content=\"T√¥i kh√¥ng th√≠ch nh·ªØng n∆°i ƒë√¥ng ng∆∞·ªùi\") , ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ps8C4ike2cA",
        "outputId": "b199c17a-7368-488f-a528-7df1bd2738b3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator = OllamaGenerator(model=\"llama3.1\",\n",
        "                            url = \"http://103.220.68.101:11434/api/generate\",\n",
        "                            generation_kwargs={\n",
        "                              \"num_predict\": 100,\n",
        "                              \"temperature\": 0.9,\n",
        "                            })"
      ],
      "metadata": {
        "id": "c9ox0tbzfF6e"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = Pipeline()\n",
        "pipe.add_component(\"retriever\", InMemoryBM25Retriever(document_store=docstore))\n",
        "pipe.add_component(\"prompt_builder\", PromptBuilder(template=template))\n",
        "pipe.add_component(\"llm\", generator)\n",
        "pipe.connect(\"retriever\", \"prompt_builder.documents\")\n",
        "pipe.connect(\"prompt_builder\", \"llm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tb6sztdqgGOa",
        "outputId": "d9834517-eeab-4676-fbd0-928a44d01442"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<haystack.core.pipeline.pipeline.Pipeline object at 0x79f1eaf70f10>\n",
              "üöÖ Components\n",
              "  - retriever: InMemoryBM25Retriever\n",
              "  - prompt_builder: PromptBuilder\n",
              "  - llm: OllamaGenerator\n",
              "üõ§Ô∏è Connections\n",
              "  - retriever.documents -> prompt_builder.documents (List[Document])\n",
              "  - prompt_builder.prompt -> llm.prompt (str)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#query=\"what is my favorite sport?\"\n",
        "query=\"B·∫°n y√™u th√≠ch m√¥n th·ªÉ thao n√†o?\"\n",
        "result = pipe.run({\"prompt_builder\": {\"query\": query}, \"retriever\": {\"query\": query}})"
      ],
      "metadata": {
        "id": "znHZPKowgRAj"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3z094pTg0tM",
        "outputId": "4440d57f-b689-432b-e326-9dc5960dd25c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'llm': {'replies': ['C√¢u tr·∫£ l·ªùi ph√π h·ª£p nh·∫•t cho c√¢u h·ªèi n√†y s·∫Ω l√†:\\n\\nB√≥ng ƒë√°!\\n\\nL√Ω do l√† trong th√¥ng tin ƒë√£ cho, ƒë√£ ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p r·∫±ng \"M√¥n th·ªÉ thao y√™u th√≠ch c·ªßa t√¥i l√† b√≥ng ƒë√°\".'], 'meta': [{'model': 'llama3.1', 'created_at': '2024-08-26T02:46:00.4282917Z', 'done': True, 'done_reason': 'stop', 'context': [128009, 128006, 882, 128007, 1432, 22818, 279, 2768, 2038, 11, 4320, 279, 3488, 382, 2014, 1473, 44, 62552, 100540, 116993, 103755, 104672, 60835, 102598, 39015, 109385, 108972, 271, 127806, 104672, 112199, 120221, 271, 127806, 54137, 104672, 100557, 105201, 109708, 100524, 271, 127806, 54137, 104672, 113354, 96182, 102637, 100705, 3355, 5080, 101792, 108546, 1432, 14924, 25, 112377, 103755, 104672, 107551, 100540, 116993, 102176, 7801, 128009, 128006, 78191, 128007, 271, 34, 101208, 106595, 106866, 105091, 100827, 101071, 2665, 106821, 107193, 97635, 100770, 39015, 1473, 33, 102818, 108972, 2268, 43, 20195, 656, 39015, 70186, 93530, 25826, 80226, 2665, 11, 80226, 64578, 101218, 107467, 103456, 330, 44, 62552, 100540, 116993, 103755, 104672, 60835, 102598, 39015, 109385, 108972, 3343], 'total_duration': 16333026200, 'load_duration': 5752008700, 'prompt_eval_count': 69, 'prompt_eval_duration': 391769000, 'eval_count': 47, 'eval_duration': 10187030000}]}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jvsOlU2Zg3i3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}